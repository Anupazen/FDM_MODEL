# -*- coding: utf-8 -*-
"""FDM_Group_Project _new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oik2DZrutQKZMMfP3KJr7HErXfGeof46
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
# %matplotlib inline
import matplotlib 
matplotlib.rcParams["figure.figsize"] = (20,10)
import plotly.express as px

# from google.colab import drive
# drive.mount('/content/drive')

# %cd /content/drive/MyDrive/FDM_Project

#@title Loading Dataset
df1 = pd.read_excel('LoanDataset.xlsx')
df1.head()

df1.describe()[['yearly_salary','total_credit_card_limit','avg_percentage_credit_card_limit_used_last_year','saving_amount','checking_amount','age']]

#@title Remove Outliers

def find_outliers_IQR(df):

   q1=df.quantile(0.25)

   q3=df.quantile(0.75)

   IQR=q3-q1

   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]

   return outliers

# def drop_outliers_IQR(df):

#    q1=df.quantile(0.25)

#    q3=df.quantile(0.75)

#    IQR=q3-q1

#    not_outliers = df[~((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]

#    outliers_dropped = outliers.dropna().reset_index()

#    return outliers_dropped

# total_credit_card_limit   -> ok
# saving_amount	            -> no
# checking_amount           -> no
# yearly_salary             -> ok

outliers = find_outliers_IQR(df1['total_credit_card_limit'])

print('number_of_outliers :'+ str(len(outliers)))
print('max_outlier value: '+ str(outliers.max()))

print('min outlier value: '+ str(outliers.min()))

fig = px.box(df1,'total_credit_card_limit')

fig.show()

df_new_1=df1[df1.total_credit_card_limit.isin(outliers) == False]
outliers1 = find_outliers_IQR(df_new_1['total_credit_card_limit'])

print('number_of_outliers :'+ str(len(outliers1)))
print('max_outlier value: '+ str(outliers1.max()))
print('min outlier value: '+ str(outliers1.min()))

fig = px.box(df_new_1,'total_credit_card_limit')
fig.show()

outliers_n2 = find_outliers_IQR(df_new_1['checking_amount'])

print('number_of_outliers :'+ str(len(outliers_n2)))
print('max_outlier value: '+ str(outliers_n2.max()))

print('min outlier value: '+ str(outliers_n2.min()))

fig = px.box(df_new_1,'checking_amount')

fig.show()

df_new_2=df_new_1[df_new_1.checking_amount.isin(outliers_n2) == False]
outliers2 = find_outliers_IQR(df_new_2['checking_amount'])

print('number_of_outliers :'+ str(len(outliers2)))
print('max_outlier value: '+ str(outliers2.max()))
print('min outlier value: '+ str(outliers2.min()))

fig = px.box(df_new_2,'checking_amount')
fig.show()

outliers_n3 = find_outliers_IQR(df_new_2['saving_amount'])

print('number_of_outliers :'+ str(len(outliers_n3)))
print('max_outlier value: '+ str(outliers_n3.max()))

print('min outlier value: '+ str(outliers_n3.min()))

fig = px.box(df_new_2,'saving_amount')

fig.show()

df_new_3=df_new_2[df_new_2.saving_amount.isin(outliers_n3) == False]
outliers2 = find_outliers_IQR(df_new_3['saving_amount'])

print('number_of_outliers :'+ str(len(outliers2)))
print('max_outlier value: '+ str(outliers2.max()))
print('min outlier value: '+ str(outliers2.min()))

fig = px.box(df_new_3,'saving_amount')
fig.show()

outliers = find_outliers_IQR(df_new_3['yearly_salary'])

print('number_of_outliers :'+ str(len(outliers)))
print('max_outlier value: '+ str(outliers.max()))

print('min outlier value: '+ str(outliers.min()))

fig = px.box(df_new_3,'yearly_salary')

fig.show()

df_new_4=df_new_3[df_new_3.yearly_salary.isin(outliers) == False]
outliers2 = find_outliers_IQR(df_new_4['yearly_salary'])

print('number_of_outliers :'+ str(len(outliers2)))
print('max_outlier value: '+ str(outliers2.max()))
print('min outlier value: '+ str(outliers2.min()))

fig = px.box(df_new_4,'yearly_salary')
fig.show()

outliers = find_outliers_IQR(df_new_4['age'])

print('number_of_outliers :'+ str(len(outliers)))
print('max_outlier value: '+ str(outliers.max()))

print('min outlier value: '+ str(outliers.min()))

fig = px.box(df_new_4,'age')

fig.show()

outliers = find_outliers_IQR(df_new_4['dependent_number'])

print('number_of_outliers :'+ str(len(outliers)))
print('max_outlier value: '+ str(outliers.max()))

print('min outlier value: '+ str(outliers.min()))

fig = px.box(df_new_4,'dependent_number')

fig.show()

df1=df_new_4.copy()

###################################################################################################################################################################################

###################################################################################################################################################################################

#@title Binning
df2= df1[(df1.loan_granted>0)]

df2.head()

df2['loan_granted'].unique()

df3=df2.drop(['loan_granted'],axis='columns')

df3.head()

df3['loan_purpose'].unique()

df3['loan_repaid'].unique()

df3['is_first_loan'].unique()

df3['fully_repaid_previous_loans'].unique() #change Nan to -1 ---->> Done

df4=df3.copy()

df4

df4["fully_repaid_previous_loans"].fillna(-1, inplace=True)

df4

df4['fully_repaid_previous_loans'].unique()

df4['currently_repaying_other_loans'].unique() #change Nan to -1 ---->> Done

df5=df4.copy()

df5["currently_repaying_other_loans"].fillna(-1, inplace=True)

df5

df5['currently_repaying_other_loans'].unique()

##### Start From Here #####

max(df5['total_credit_card_limit'])

min(df5['total_credit_card_limit'])

len(df5)

df5['total_credit_card_limit'].unique() #Put to bins

bins = [ -1, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000 ]
label=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]

df5['total_credit_card_limit_bin']= pd.cut(df5['total_credit_card_limit'],bins,labels=label)

df6=df5.copy()

df6

df7=df6.copy()

df7=df7.drop(['total_credit_card_limit'],axis='columns')

df7

df7['avg_percentage_credit_card_limit_used_last_year'].unique() #convert Nan (Nan comes when the total credit card limit is 0) and put to bins

df7['loan_repaid'].unique()

df7['is_first_loan'].unique()

df7['fully_repaid_previous_loans'].unique()

df7['currently_repaying_other_loans'].unique()

df7['total_credit_card_limit_bin'].unique()

min(df7['total_credit_card_limit_bin'])

df7['avg_percentage_credit_card_limit_used_last_year'].fillna(-1, inplace=True) #Credit limit 0, limit used last year 0 -> -1

df7['avg_percentage_credit_card_limit_used_last_year'].unique()

max(df7['avg_percentage_credit_card_limit_used_last_year'])

min(df7['avg_percentage_credit_card_limit_used_last_year'])

df8 = df7.copy()

bins2 = [ -1.2, 0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]
label2 =[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

df8['avg_percentage_credit_card_limit_used_last_year_bin']= pd.cut(df8['avg_percentage_credit_card_limit_used_last_year'],bins2,labels=label2)

df8

df8['avg_percentage_credit_card_limit_used_last_year_bin'].unique()

df9 = df8.copy()

df9=df9.drop(['avg_percentage_credit_card_limit_used_last_year'],axis='columns')

df9

max(df9["saving_amount"])

min(df9["saving_amount"])

df9["saving_amount"].unique()

df9['yearly_salary'].unique()

max(df9['yearly_salary'])

min(df9['yearly_salary'])

df10=df9.copy()

bins3 = [-1,10000,20000,30000,40000,50000,60000,70000,80000,90000,100000,110000,120000,130000,140000,150000]
label3 =[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12,13,14,15]

df10['yearly_salary_bin']= pd.cut(df10['yearly_salary'],bins3,labels=label3)

df10.head()

df10['yearly_salary_bin'].unique()

df11=df10.drop(['yearly_salary'],axis='columns')

df11.head()

df11['age'].unique()

max(df11['age'])

df12=df11.copy()

bins4 = [15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95]
label4 =[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12,13,14,15,16]

df12['age_bin']= pd.cut(df12['age'],bins4,labels=label4)

df12.head()

df13=df12.drop(['age'],axis='columns')

df14=df13.copy()

max(df13['checking_amount'])

min(df13['saving_amount'])

df15=df14.copy()

bins5 = [-1000,0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000]
label5 =[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12,13,14,15,16]

df15['saving_amount_bin']= pd.cut(df15['saving_amount'],bins5,labels=label5)

df15.head()

df16=df15.drop(['saving_amount'],axis='columns')

df16.head()

df17=df16.copy()

max(df17['checking_amount'])

bins6 = [-1000,0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000]
label6 =[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12,13,14,15,16]

df17['checking_amount_bin']= pd.cut(df17['checking_amount'],bins5,labels=label5)

df17.head()

df18=df17.drop(['checking_amount'],axis='columns')

df18.head()

df18['age_bin'].unique()

df18.head()

dummies=pd.get_dummies(df18.loan_purpose)

df19=pd.concat([df18,dummies],axis='columns')

df20=df19.drop('loan_purpose',axis='columns')

df20.head()

df21=df20.drop('loan_id',axis='columns')

df22=df21.drop('date',axis='columns')

df22.head()

training_data = df22.sample(frac=0.8, random_state=25)
testing_data = df22.drop(training_data.index)

print(f"No. of training examples: {training_data.shape[0]}")
print(f"No. of testing examples: {testing_data.shape[0]}")

# No. of training examples: 120
# No. of testing examples: 30

training_list_predict = training_data.loan_repaid.values.tolist()
print (training_list_predict)

training_list_input=training_data.drop('loan_repaid',axis='columns')
print (training_list_input)

pip install pygad

import numpy
import pygad
import pygad.nn
import pygad.gann

#@title Model
from sklearn import model_selection
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV,KFold

svcl=SVC(C=1,kernel='linear')

svcl.fit(training_list_input,training_list_predict)

testing_list_predict = testing_data.loan_repaid.values.tolist()
print (testing_list_predict)

testing_list_input=testing_data.drop('loan_repaid',axis='columns')
print (testing_list_input)

y_pred=svcl.predict(testing_list_input)

accuracy_score(testing_list_predict,y_pred)

confusion_matrix(testing_list_predict,y_pred)

sns.heatmap(confusion_matrix(testing_list_predict,y_pred),annot=True,fmt="g")
plt.ylabel("Actual")
plt.show()

y_pred=svcl.predict([[0,1.0,0.0,1,4,6,4,2,9,5,4,0,0,0,0,1]])

print(y_pred)